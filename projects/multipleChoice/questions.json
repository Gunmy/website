[
{
"question": "Hva er sannsynligheten for feilklassifisering ifølge Gini-urenhet?",
"fake": [
"Sannsynligheten for feilklassifisering er lik andelen av positive datapunkter.",
"Gini-urenhet vurderer alltid at datasettene er perfekte."
],
"true": [
"Gini-urenhet gir sannsynligheten for feilklassifisering basert på klassedistribusjonen.",
"Lav Gini-urenhet betyr at de fleste datapunkter tilhører én klasse."
]
},
{
"question": "Hvilken egenskap har sigmoid-funksjonen i logistisk regresjon?",
"fake": [
"Den er alltid lineær.",
"Den returnerer sannsynligheter mellom -1 og 1."
],
"true": [
"Den mapper reelle tall til intervallet (0,1).",
"Den brukes ofte som en aktiveringsfunksjon i nevrale nettverk."
]
},
{
"question": "Hva er hovedfordelen med logistisk regresjon som en klassifiseringsmodell?",
"fake": [
"Den fungerer bare på binære variabler.",
"Den gir alltid perfekte resultater uten datarensing."
],
"true": [
"Den kan beregne sannsynligheter for to klasser.",
"Den bruker sigmoid-funksjonen for å begrense prediksjonene mellom 0 og 1."
]
},
{
"question": "Hvilken rolle spiller gradient descent i trening av maskinlæringsmodeller?",
"fake": [
"Det sikrer alltid det globale maksimumet.",
"Det brukes til å redusere treningsdatasettet."
],
"true": [
"Det finner minimum av tapsfunksjonen.",
"Det oppdaterer modellens parametere iterativt basert på gradienter."
]
},
{
"question": "Hva er et vanlig problem med å trene en modell på ubalanserte data?",
"fake": [
"Modellen vil overfitte til den mindre representerte klassen.",
"Modellen klarer ikke å konvergere under trening."
],
"true": [
"Modellen kan favorisere den større klassen.",
"Metrikker som treffsikkerhet kan være misvisende."
]
},
{
"question": "Hva er hensikten med MinMaxScaler i preprosessering av data?",
"fake": [
"Den legger til støy i datasettet.",
"Den fjerner dupliserte datapunkter."
],
"true": [
"Den skalerer data til et definert intervall, ofte [0, 1].",
"Den reduserer effekten av forskjellige skalaer på funksjoner."
]
},
{
"question": "Hva er ROC-kurven brukt til i maskinlæring?",
"fake": [
"For å finne hvor mange datapunkter som mangler i datasettet.",
"For å plotte fordelingen av trenings- og testdata."
],
"true": [
"For å vise sammenhengen mellom TPR og FPR for ulike terskler.",
"For å evaluere en klassifiseringsmodells ytelse uavhengig av terskel."
]
},

{
"question": "Hva er et typisk trekk ved Naïve Bayes-modellen?",
"fake": [
"Den forutsetter at alle klasser har lik sannsynlighet.",
"Den krever store treningsdatasett for å fungere."
],
"true": [
"Den antar at alle funksjoner er uavhengige.",
"Den bruker Bayes’ teorem for sannsynlighetsberegning."
]
},
{
"question": "Hva brukes Gini-impurity til i beslutningstrær?",
"fake": [
"Å beregne sannsynligheten for overfitting.",
"Å finne optimale parametere for modellen."
],
"true": [
"Å måle hvor rene data er etter en splitt.",
"Å evaluere splittingkriterier for å bygge trær."
]
},
{
"question": "Hva er en fordel med krysvalidering i maskinlæring?",
"fake": [
"Det krever ikke deling av data i trenings- og testsett.",
"Det reduserer kompleksiteten til modellen."
],
"true": [
"Det gir en mer pålitelig evaluering av modellens ytelse.",
"Det reduserer risikoen for overfitting til spesifikke treningsdata."
]
},
{
"question": "Hva er hovedmålet med Principal Component Analysis (PCA)?",
"fake": [
"Å øke dimensjonaliteten til dataene.",
"Å erstatte alle variabler med tilfeldige verdier."
],
"true": [
"Å redusere dimensjonaliteten samtidig som mest mulig informasjon beholdes.",
"Å finne komponenter som forklarer mest variasjon i dataene."
]
},
{
"question": "Hva representerer en løvnode i et beslutningstre?",
"fake": [
"En node som alltid splitter dataene videre.",
"En node som inneholder alle treningsdata."
],
"true": [
"En node som gir en predikert verdi.",
"En avsluttende node uten flere splittingkriterier."
]
},


{
"question": "Hvilken av disse egenskapene må være oppfylt for at et datapunkt skal være en anomali i datasettet?",
"fake": [
"Datapunktet kan plukkes ut ved hjelp av k-means clustering og persentiler",
"Datapunktet markeres som en outlier av DBSCAN",
"Datapunktet er rødt når vi visualiserer det"
],
"true": [
"Datapunktet er langt unna alle klyngesentre"
]
},
{
"question": "Hva er fordelene med å bruke ensemble-metoder som bagging?",
"fake": [
"Reduserer alltid modellens kompleksitet",
"Garanterer høyere presisjon i alle datasett"
],
"true": [
"Reduserer variansen i modellprediksjoner",
"Kombinerer flere svake lærere til en sterk modell"
]
},
{
"question": "Hvilken av disse brukes til å justere modellens ytelse på ubalanserte datasett?",
"fake": [
"Overføre alle datapunktene til en uniform distribusjon",
"Fjerne data fra begge klasser for balanse"
],
"true": [
"Oversampling av minoritetsklassen",
"Vekting av tapsfunksjonen basert på klassedistribusjon"
]
},
{
"question": "Hva er en sannhet om funksjoner i k-means clustering?",
"fake": [
"K-means kan håndtere variabler som er sterkt avhengige av hverandre.",
"K-means fungerer alltid best på ubalanserte datasett."
],
"true": [
"K-means avhenger av initialisering av klyngesentrene.",
"K-means forsøker å minimere avstanden mellom datapunkter og klyngesentre."
]
},
{
"question": "Hva er en vanlig utfordring med gradient descent?",
"fake": [
"Det garanterer alltid global optimalisering.",
"Det kan ikke tilpasses læringsraten under trening."
],
"true": [
"Det kan sette seg fast i lokale minima.",
"Læringsraten må justeres for å unngå konvergeringsproblemer."
]
},
{
"question": "Hvilket av følgende er en fordel med å bruke cross entropy som tapsfunksjon?",
"fake": [
"Det krever ikke differensierbarhet av modellens parametere.",
"Det fungerer bare for uveiledet læring."
],
"true": [
"Det håndterer sannsynligheter på en intuitiv måte.",
"Det belønner høye sannsynligheter for korrekte klasser."
]
},
{
"question": "Hva er nødvendig for å bruke en nevralt nettverk i klassifisering?",
"fake": [
"Alle funksjoner må være normalisert til heltall.",
"Ingen gradientberegninger er nødvendig."
],
"true": [
"En aktiveringsfunksjon som sigmoid eller ReLU.",
"Bakpropagering for å justere vektene."
]
},
{
"question": "Hvilken av disse metodene kan brukes for å redusere dimensjonaliteten i datasettet?",
"fake": [
"k-means clustering",
"Gradient descent"
],
"true": [
"Principal Component Analysis (PCA)",
"t-SNE"
]
},
{
"question": "Hvilken av følgende er en egenskap ved bagging?",
"fake": [
"Bruker kun én modell til prediksjon.",
"Fungerer bare på store datasett."
],
"true": [
"Kombinerer flere modeller for å redusere variansen.",
"Trener modeller på ulike bootstrap-prøver av data."
]
},
{
"question": "Hva er en fordel med boosting i ensemble-metoder?",
"fake": [
"Øker alltid modellens robusthet mot overfitting.",
"Fungerer kun for lineære data."
],
"true": [
"Fokuserer på feilprediksjoner i tidligere modeller.",
"Forbedrer ytelsen ved å kombinere svakere modeller."
]
},
{
"question": "Hva brukes ROC-kurven til?",
"fake": [
"For å velge den beste hyperparameteren for k-means.",
"For å evaluere datafordelingen i uveiledet læring."
],
"true": [
"For å analysere trade-off mellom TPR og FPR.",
"For å evaluere klassifiseringsmodeller over ulike terskler."
]
},
{
"question": "Hva skjer dersom learning rate er for høy i gradient descent?",
"fake": [
"Modellen konvergerer alltid raskere.",
"Gradientene blir konstant null."
],
"true": [
"Modellen kan hoppe over minimumspunktet.",
"Treningen kan bli ustabil."
]
},
{
"question": "Hva er en sannhet om Gini impurity?",
"fake": [
"Den kan ikke brukes på datasett med mer enn to klasser.",
"Den måler maksimal usikkerhet i et datasett."
],
"true": [
"Den angir sannsynligheten for feilklassifisering.",
"Lav Gini impurity tilsier høy klassehomogenitet."
]
},
{
"question": "Hva er et mål for dimensional curse i maskinlæring?",
"fake": [
"Det gjør modellen mer nøyaktig i høyere dimensjoner.",
"Det forbedrer generaliseringen av alle modeller."
],
"true": [
"Det øker mengden data som kreves for trening.",
"Det kan føre til dårlig ytelse på testdata."
]
},
{
"question": "Hva er en typisk egenskap ved ensemble-metoder?",
"fake": [
"De krever alltid store mengder data.",
"De reduserer alltid overfitting."
],
"true": [
"De kombinerer flere modeller for å forbedre ytelsen.",
"De kan redusere varians eller bias avhengig av metoden."
]
},
{
"question": "Hva er hovedforskjellen mellom bagging og boosting?",
"fake": [
"Boosting bruker tilfeldige prøver av data, mens bagging fokuserer på feil.",
"Bagging fungerer bare for regresjonsoppgaver."
],
"true": [
"Bagging reduserer variansen, mens boosting reduserer bias.",
"Boosting bygger på hver modell sekvensielt, mens bagging bygger uavhengig."
]
},
{
"question": "Hva er en nøkkeltilnærming i dimensjonsreduksjon med PCA?",
"fake": [
"Å finne nye aksler som maksimerer klusterdistansen.",
"Å redusere variansen i datasettet."
],
"true": [
"Å finne nye aksler som maksimerer variansen i dataene.",
"Å redusere antall dimensjoner mens informasjon bevares."
]
},
{
"question": "Hva kjennetegner aktiveringsfunksjonen ReLU?",
"fake": [
"Den mapper alle inputverdier til 0 eller 1.",
"Den er alltid lineær."
],
"true": [
"Den returnerer 0 for negative inputverdier.",
"Den er skalerbar for store verdier uten å mettes."
]
},
{
"question": "Hva er en viktig årsak til å bruke kryssvalidering?",
"fake": [
"Det reduserer datarensingsbehovet.",
"Det krever færre data for å trene modellen."
],
"true": [
"Det gir mer robust evaluering av modellen.",
"Det bidrar til å avdekke overfitting."
]
},
{
"question": "Hva er Bayes' teorem sentralt i?",
"fake": [
"Prediksjon av kontinuerlige variabler i regresjonsmodeller.",
"Trening av dype nevrale nettverk."
],
"true": [
"Estimering av sannsynligheter gitt betingelser.",
"Naïve Bayes-algoritmer for klassifisering."
]
},
{
"question": "Hva er en typisk utfordring med å bruke decision trees?",
"fake": [
"De fungerer kun for kontinuerlige data.",
"De kan bare brukes på små datasett."
],
"true": [
"De kan overtilpasse dataene hvis de er for dype.",
"De er sensitive for små endringer i dataene."
]
},
{
"question": "Hva er fordelen med en weighted loss function på ubalanserte datasett?",
"fake": [
"Den gjør alltid modellen raskere.",
"Den reduserer alltid variansen i dataene."
],
"true": [
"Den gir høyere vekt til feilprediksjoner på minoritetsklassen.",
"Den kan forbedre modellens evne til å håndtere sjeldne klasser."
]
},
{
"question": "Hvilket mål brukes i decision trees for å redusere usikkerhet?",
"fake": [
"ROC AUC",
"Precision-Recall"
],
"true": [
"Entropi",
"Gini impurity"
]
},
{
"question": "Hva er en ulempe ved å bruke oversampling på ubalanserte datasett?",
"fake": [
"Det fører alltid til underfitting.",
"Det reduserer modellens evne til å lære minoritetsklasser."
],
"true": [
"Det kan føre til overfitting på dupliserte datapunkter.",
"Det kan forlenge treningstiden."
]
},
{
"question": "Hva er en sannhet om clustering-metoden k-means?",
"fake": [
"Den finner alltid globale optima.",
"Den krever ikke at klyngene er sfæriske."
],
"true": [
"Den grupperer datapunkter basert på nærhet til klyngesentre.",
"Den kan være sensitiv for valg av initiale klyngesentre."
]
},
{
"question": "Hva er hovedformålet med DBSCAN som clustering-metode?",
"fake": [
"Å minimere antall klynger i datasettet.",
"Å kreve like mange datapunkter i hver klynge."
],
"true": [
"Å identifisere klynger med ulik tetthet.",
"Å markere datapunkter som støy hvis de ikke tilhører en klynge."
]
},
{
"question": "Hva er fordelen med å bruke t-SNE for dimensjonsreduksjon?",
"fake": [
"Den øker dimensjonaliteten i dataene.",
"Den fungerer best for numeriske variable uten støy."
],
"true": [
"Den visualiserer høy-dimensjonale data i lavere dimensjoner.",
"Den bevarer lokale strukturer i dataene."
]
},
{
"question": "Hva er en sannhet om anomalideteksjon med Isolation Forest?",
"fake": [
"Den krever alltid data med lineær sammenheng.",
"Den kan kun brukes med balanserte datasett."
],
"true": [
"Den bruker tilfeldig deling av data for å isolere anomalier.",
"Den er effektiv for store datasett."
]
},
{
"question": "Hvilken av disse er en fordel med bagging?",
"fake": [
"Den øker alltid kompleksiteten i modellen.",
"Den gir høy bias i modellprediksjonene."
],
"true": [
"Den reduserer variansen i prediksjonene.",
"Den bruker bootstrap-prøver for robust modelltrening."
]
},
{
"question": "Hva er hovedutfordringen ved å bruke boosting?",
"fake": [
"Den gir alltid en høy varians i modellen.",
"Den krever minst én svake modell med perfeksjon."
],
"true": [
"Den kan være utsatt for overfitting på små datasett.",
"Den bygger på feilene fra tidligere modeller, noe som kan akkumulere."
]
},
{
"question": "Hva brukes precision og recall til i klassifiseringsmodeller?",
"fake": [
"Å evaluere modellens prediksjoner i kontinuerlige data.",
"Å redusere mengden treningsdata."
],
"true": [
"Å måle modellens evne til å fange opp positive klasser.",
"Å evaluere trade-off mellom korrekt klassifisering og falske alarmer."
]
},
{
"question": "Hva er et vanlig problem med overfitting i beslutningstrær?",
"fake": [
"Modellen fungerer aldri på treningsdata.",
"Den reduserer kompleksiteten i treet."
],
"true": [
"Modellen tilpasser seg for mye til treningsdataene.",
"Modellen presterer dårlig på nye, ukjente data."
]
},
{
"question": "Hva er fordelen med å bruke Random Forest i stedet for et enkelt beslutningstre?",
"fake": [
"Det eliminerer behovet for data preprosessering.",
"Det krever færre data for trening."
],
"true": [
"Det reduserer overfitting ved å kombinere flere trær.",
"Det øker robustheten til modellen ved å bruke tilfeldige underprøver av data."
]
},
{
"question": "Hva er en vanlig egenskap ved gradient boost-modeller?",
"fake": [
"De bruker kun tilfeldige splittingkriterier.",
"De eliminerer alltid støy i dataene."
],
"true": [
"De kombinerer svakere modeller sekvensielt for bedre ytelse.",
"De justerer seg basert på feilene fra tidligere modeller."
]
},
{
"question": "Hva skjer dersom en ROC AUC-verdi er nær 0.5?",
"fake": [
"Modellen har høy treffsikkerhet.",
"Modellen overfitter til treningsdataene."
],
"true": [
"Modellen er ikke bedre enn tilfeldig gjetning.",
"Modellen mangler diskrimineringsevne."
]
},
{
"question": "Hva er formålet med å plotte confusion matrix?",
"fake": [
"Å visualisere alle hyperparametrene i modellen.",
"Å evaluere korrelasjonen mellom funksjoner."
],
"true": [
"Å vise riktig og feil klassifisering i alle klasser.",
"Å evaluere hvordan modellen presterer på ulike klasser."
]
},
{
"question": "Hva er hovedformålet med clustering-metoder i maskinlæring?",
"fake": [
"Å redusere mengden data i datasettet.",
"Å finne sannsynligheten for klassifisering."
],
"true": [
"Å gruppere lignende datapunkter basert på egenskaper.",
"Å finne strukturer i umerkede datasett."
]
},
{
"question": "Hva er en ulempe ved å bruke decision trees?",
"fake": [
"De kan ikke trenes på kontinuerlige data.",
"De fungerer kun på små datasett."
],
"true": [
"De kan være utsatt for overfitting.",
"De har ofte høy varians i prediksjoner."
]
},
{
"question": "Hva er en sannhet om feature scaling i maskinlæring?",
"fake": [
"Det kreves bare for klassifiseringsmodeller.",
"Det brukes kun for å fjerne nullverdier i datasettet."
],
"true": [
"Det gjør at funksjoner på forskjellige skalaer kan sammenlignes.",
"Det forbedrer ytelsen til algoritmer som k-means og gradient descent."
]
},
{
"question": "Hva er fordelen med å bruke PCA som en metode for dimensjonsreduksjon?",
"fake": [
"Den øker alltid mengden data i datasettet.",
"Den reduserer variansen i datasettet."
],
"true": [
"Den finner de viktigste komponentene som forklarer variasjon i dataene.",
"Den reduserer kompleksiteten i høy-dimensjonale data."
]
},

{
"question": "Hvilken egenskap er nødvendig for en tapsfunksjon i gradient descent?",
"fake": [
"Den må alltid være positiv.",
"Den må være diskret.",
"Den må gi samme verdi for alle datapunkter."
],
"true": [
"Den må være deriverbar."
]
},
{
"question": "Hva er et viktig kriterium for å velge antall klynger i k-means?",
"fake": [
"Antallet må være lik antall datapunkter.",
"Antallet bestemmes alltid automatisk.",
"Antallet bør alltid være et primtall."
],
"true": [
"Antallet kan velges ved bruk av metoder som Elbow-metoden."
]
},
{
"question": "Hva skjer hvis læringsraten i gradient descent er for lav?",
"fake": [
"Modellen hopper over det globale minimumet.",
"Tapet øker for hver iterasjon.",
"Modellen blir mindre generaliserbar."
],
"true": [
"Treningen tar lengre tid å konvergere."
]
},
{
"question": "Hvilken av følgende brukes til å evaluere en klassifiseringsmodell?",
"fake": [
"Arealet under precision-kurven (AUP).",
"Gradientkurven.",
"Loss-plottet."
],
"true": [
"ROC AUC."
]
},
{
"question": "Hva brukes Random Forest til i maskinlæring?",
"fake": [
"Å redusere datasettets størrelse.",
"Å optimalisere læringsraten.",
"Å redusere dimensjonaliteten i dataene."
],
"true": [
"Å kombinere flere beslutningstrær for bedre prediksjon."
]
},
{
"question": "Hva er en fordel med å bruke standardisering av data?",
"fake": [
"Den endrer alltid dataenes fordeling til å bli uniform.",
"Den fjerner støy fra datasettet.",
"Den dobler antall datapunkter i datasettet."
],
"true": [
"Den setter data til en skala med gjennomsnitt 0 og standardavvik 1."
]
},
{
"question": "Hva er en nøkkelutfordring med clustering?",
"fake": [
"Det krever alltid merkede data.",
"Resultatene er alltid deterministiske.",
"Det kan kun brukes for kontinuerlige variabler."
],
"true": [
"Resultatene kan avhenge av avstandsmål og initialisering."
]
},
{
"question": "Hvilken metode brukes til dimensjonsreduksjon?",
"fake": [
"Bagging.",
"DBSCAN.",
"Logistisk regresjon."
],
"true": [
"Principal Component Analysis (PCA)."
]
},
{
"question": "Hva er en fordel med decision trees?",
"fake": [
"De krever alltid balanserte datasett.",
"De kan ikke håndtere kontinuerlige variabler.",
"De krever en fast dybde for å fungere."
],
"true": [
"De er enkle å tolke og visualisere."
]
},
{
"question": "Hvilken rolle spiller entropi i maskinlæring?",
"fake": [
"Den brukes til å redusere datastørrelsen.",
"Den erstatter tapsfunksjonen i alle klassifiseringsmodeller.",
"Den gir alltid en nøyaktig prediksjon."
],
"true": [
"Den brukes til å måle usikkerhet i datasett."
]
},
{
"question": "Hva er en svakhet ved k-means clustering?",
"fake": [
"Det kan ikke brukes på høydimensjonale data.",
"Det støtter ikke numeriske variabler.",
"Det gir alltid samme klynger uavhengig av startverdier."
],
"true": [
"Det kan bli fanget i lokale minima."
]
},
{
"question": "Hva er viktig for en vellykket prediktiv modell?",
"fake": [
"Den må være overtilpasset treningsdata.",
"Den må ignorere uavhengige variabler.",
"Den må ha så mange parametere som mulig."
],
"true": [
"Den må generalisere godt til nye data."
]
},
{
"question": "Hvilken av disse metodene kan brukes til å håndtere ubalanserte datasett?",
"fake": [
"Kombinere alle datapunktene i én klasse.",
"Øke læringsraten i modellen.",
"Ignorere minoritetsklassen helt."
],
"true": [
"Oversampling av minoritetsklassen."
]
},
{
"question": "Hva er en utfordring med høy-dimensjonale data?",
"fake": [
"Det øker alltid modellens presisjon.",
"Det eliminerer behovet for regularisering.",
"Det reduserer variansen i modellen."
],
"true": [
"Det kan føre til dimensjonsforbannelsen."
]
},
{
"question": "Hva er en viktig egenskap ved decision trees?",
"fake": [
"De kan bare brukes til regresjon.",
"De krever alltid kontinuerlige data.",
"De trenger minst 100 funksjoner for å trenes."
],
"true": [
"De kan brukes til både klassifisering og regresjon."
]
},
{
"question": "Hvilken av disse er en viktig årsak til å bruke ensemble-metoder?",
"fake": [
"De øker alltid datamengden.",
"De reduserer behovet for validering.",
"De eliminerer behovet for tuning av hyperparametere."
],
"true": [
"De kan redusere bias og varians i modellprediksjoner."
]
},
{
"question": "Hva er en fordel med bruk av ROC AUC som evaluering?",
"fake": [
"Det måler alltid hvor raskt en modell trener.",
"Det gir detaljert informasjon om alle datapunkter.",
"Det kan kun brukes på uveiledet læring."
],
"true": [
"Det evaluerer modellen over ulike klassifiseringsterskler."
]
},
{
"question": "Hva er en nøkkelfordel ved å bruke t-SNE for visualisering?",
"fake": [
"Det gir deterministiske resultater.",
"Det fungerer kun på binære datasett.",
"Det krever svært små datasett."
],
"true": [
"Det bevarer lokale strukturer i høy-dimensjonale data."
]
},
{
"question": "Hva er en viktig rolle til en confusion matrix?",
"fake": [
"Å identifisere hvilke data som må normaliseres.",
"Å analysere korrelasjoner mellom variabler.",
"Å redusere dimensjonaliteten til dataene."
],
"true": [
"Å visualisere korrekt og feil klassifisering i ulike klasser."
]
},
{
"question": "Hva er en nøkkelutfordring ved å bruke boosting?",
"fake": [
"Det gir alltid dårlig ytelse på treningsdata.",
"Det fjerner alle feil i datasettet.",
"Det krever bare én svake modell."
],
"true": [
"Det kan føre til overfitting på små datasett."
]
},

{
"question": "Hva er formålet med maskinlæring ifølge Tom Mitchells definisjon?",
"fake": [
"Å finne mønstre i data uten å vite hva vi leter etter.",
"Å minimere tapsfunksjonen til en modell.",
"Å automatisere programmering av datamaskiner."
],
"true": ["Å forbedre ytelsen på en oppgave T basert på erfaring E."]
},
{
"question": "Hvilke typer variabler finnes i maskinlæring?",
"fake": ["Kontinuerlige og kvalitative."],
"true": [
"Numeriske og kategoriske.",
"Kvalitative og kvantitative.",
"Diskrete og kontinuerlige."
]
},
{
"question": "Hva er en vanlig metode for å håndtere manglende data i et datasett?",
"fake": ["Standardisering.", "Bruke en LabelEncoder."],
"true": [
"Fjerne rader med metoden dropna().",
"Imputere verdier ved hjelp av snitt."
]
},
{
"question": "Hva er formålet med preprosessering av data?",
"fake": [
"Gjøre data lettere å forstå for mennesker.",
"Forbedre ytelsen til testdata.",
"Redusere størrelsen på datasettet."
],
"true": ["Klargjøre data for å kunne brukes i maskinlæringsmodeller."]
},
{
"question": "Hva er en sigmoid-funksjon?",
"fake": [
"En metode for å normalisere data.",
"En tapsfunksjon som brukes i lineær regresjon.",
"En teknikk for å trene nevrale nettverk."
],
"true": ["En funksjon som estimerer sannsynlighet mellom 0 og 1."]
},
{
"question": "Hva må en tapsfunksjon være for å kunne brukes i gradient descent?",
"fake": ["Entydig.", "Konveks."],
"true": ["Differensierbar.", "Kontinuerlig."]
},
{
"question": "Hva er rollen til læringsraten i gradient descent?",
"fake": [
"Angir hvor bratt gradienten er.",
"Bestemmer hvilken vei gradienten peker.",
"Er en del av modellens parametre."
],
"true": ["Styrer størrelsen på oppdateringene til parameterne."]
},
{
"question": "Hvilke teknikker kan brukes for å håndtere ubalanserte datasett?",
"fake": [],
"true": [
"Oversampling.",
"Bruk av vektet tapsfunksjon.",
"Endre klassifiseringsterskelen.",
"Dataaugmentering."
]
},
{
"question": "Hva er ROC-kurven nyttig for?",
"fake": [
"Analysere hvor godt modellen predikerer kontinuerlige verdier.",
"Sammenligne presisjon og recall."
],
"true": [
"Evaluere en klassifiseringsmodells ytelse over ulike terskler.",
"Måle andelen falske positive."
]
},
{
"question": "Hva representerer entropi i maskinlæring?",
"fake": [
"Differansen mellom to sannsynlighetsfordelinger.",
"Antall feilklassifiserte datapunkter."
],
"true": [
"Mengden informasjon i en sannsynlighetsfordeling.",
"Usikkerheten i en modell."
]
},
{
"question": "Hva er Naïve Bayes-modellens grunnantakelse?",
"fake": [
"Klassene er balanserte.",
"Dataene er normalfordelte.",
"Likelihood-fordelingen er kjent."
],
"true": ["Feature-verdiene er uavhengige."]
},
{
"question": "Hva er en fordel med beslutningstrær?",
"fake": ["De krever lite data for å fungere godt.", "De er robuste mot overtilpasning."],
"true": [
"De kan enkelt visualiseres.",
"De kan håndtere både numeriske og kategoriske variabler."
]
},
{
"question": "Hva måles med Gini-impurity?",
"fake": [
"Informasjonsgevinsten ved en splitt.",
"Variasjonen i datasettet.",
"Entropien til en sannsynlighetsfordeling."
],
"true": ["Sannsynligheten for feilklassifisering."]
},
{
"question": "Hvilken av følgende er en ensemble-metode?",
"fake": ["K-means clustering.", "Stochastic Gradient Descent."],
"true": ["Bagging.", "Gradient Boosting."]
},
{
"question": "Hva er formålet med kryssvalidering?",
"fake": [
"Å redusere bias i en modell.",
"Å øke antallet datapunkter i treningssettet."
],
"true": [
"Å evaluere modellens evne til å generalisere.",
"Å optimalisere hyperparametere."
]
},
{
"question": "Hvilke oppgaver er vanlige i uveiledet læring?",
"fake": ["Klassifisering."],
"true": ["Clustering.", "Dimensjonsreduksjon.", "Anomalideteksjon."]
},
{
"question": "Hva er hovedforskjellen mellom supervised og unsupervised learning?",
"fake": [
"Bruk av tapsfunksjoner.",
"Bruk av kryssvalidering.",
"Evnen til å generalisere."
],
"true": ["Tilgang på labels."]
},
{
"question": "Hva er et eksempel på en aktiveringsfunksjon i nevrale nettverk?",
"fake": [],
"true": ["Sigmoid.", "ReLU.", "Tanh.", "Softmax."]
},
{
"question": "Hva er målet med backpropagation?",
"fake": [
"Beregne tapsfunksjonen.",
"Justere læringsraten.",
"Optimalisere hyperparametere."
],
"true": ["Oppdatere modellens parametere."]
},
{
"question": "Hva er fordelen med Stochastic Gradient Descent (SGD) sammenlignet med vanlig Gradient Descent?",
"fake": [
"Det bruker alle data på en gang.",
"Det finner alltid globale minima.",
"Det er mindre følsomt for læringsraten."
],
"true": ["Det krever mindre minne."]
},

{
"question": "Hvilke deler består et beslutningstre av?",
"fake": ["Gradient-noder."],
"true": ["Rotnode.", "Beslutningsnode.", "Løvnoder."]
},
{
"question": "Hva betyr Gini-impurity i maskinlæring?",
"fake": ["Sannsynligheten for korrekt klassifisering.", "Et mål på gradientens stabilitet."],
"true": ["Et mål på datasettets renhet.", "Sannsynligheten for feilklassifisering."]
},
{
"question": "Hva representerer en \"leaf node\" i et beslutningstre?",
"fake": ["Starten av treet.", "En node med alle datainstansene.", "Et splittpunkt for dataene."],
"true": ["En node uten splits."]
},
{
"question": "Hva er formålet med entropi i beslutningstrær?",
"fake": ["Å måle sannsynligheten for feilklassifisering.", "Å beregne vekter for datainstansene."],
"true": ["Å kvantifisere usikkerhet.", "Å avgjøre splitpunkt."]
},
{
"question": "Hva er et vanlig problem ved ubalanserte datasett?",
"fake": ["Konveks optimalisering feiler."],
"true": ["Høy presisjon men lav recall.", "Overrepresentasjon av den ene klassen.", "Modellen fokuserer kun på en klasse."]
},
{
"question": "Hva betyr oversampling av data?",
"fake": ["Å fjerne data fra den overrepresenterte klassen.", "Å balansere datasettene ved vekting.", "Å redusere datasettet for bedre ytelse."],
"true": ["Å duplisere data fra den underrepresenterte klassen."]
},
{
"question": "Hva er hovedkomponenten i en ensemble-modell?",
"fake": ["En sterk lærer som samler dataene.", "Nevrale nettverk.", "Cluster-baserte prediksjoner."],
"true": ["Multiple svake lærere."]
},
{
"question": "Hvilke teknikker brukes i boosting?",
"fake": ["Sammenstilling av sterke lærere.", "Reduksjon av bias og variance.", "Øke læringsraten dynamisk."],
"true": ["Korrigering av svakere lærere."]
},
{
"question": "Hva er en fordel med bagging?",
"fake": ["Økt variabilitet i prediksjoner.", "Raskere trening av modellen."],
"true": ["Reduksjon av overtilpasning.", "Robusthet mot støy i data."]
},
{
"question": "Hvilke oppgaver kan PCA brukes til?",
"fake": ["Clustering av data.", "Økning av antall features."],
"true": ["Reduksjon av dimensjonalitet.", "Identifikasjon av hovedkomponenter."]
},
{
"question": "Hva er formålet med t-SNE?",
"fake": ["Identifisere anomalier i datasett.", "Løse lineære regresjonsproblemer."],
"true": ["Visualisere data i 2D.", "Forenkle ikke-lineær data."]
},
{
"question": "Hvilke teknikker er nyttige i anomalideteksjon?",
"fake": ["Gradient descent.", "Ensemble-modeller."],
"true": ["Isolation Forest.", "DBSCAN."]
},
{
"question": "Hva er et eksempel på reinforcement learning?",
"fake": ["En modell som analyserer data uten labels.", "En lineær regresjonsmodell.", "En ensemble-metode for beslutningstre."],
"true": ["En robot som navigerer i et rom."]
},
{
"question": "Hva er en viktig egenskap ved Markov Decision Processes?",
"fake": ["Tidligere beslutninger påvirker fremtidige.", "Konstant læringsrate.", "Redundans i systemet."],
"true": ["Uavhengighet mellom steg."]
},
{
"question": "Hva måles med Q-verdier i reinforcement learning?",
"fake": ["Variansen mellom episoder.", "Antall mulige handlinger.", "Relativ ytelse for modellen."],
"true": ["Forventet fremtidig belønning."]
},
{
"question": "Hva representerer AUC i en ROC-kurve?",
"fake": ["Presisjonen for modellen.", "Modellens evne til å håndtere ubalansert data.", "Hvor raskt modellen konvergerer."],
"true": ["Det totale arealet under ROC-kurven."]
},
{
"question": "Hvilke egenskaper har en god aktiveringsfunksjon?",
"fake": ["Konveksitet.", "Normalisering."],
"true": ["Ikke-lineæritet.", "Deriverbarhet."]
},
{
"question": "Hva er en fordel med ReLU sammenlignet med sigmoid?",
"fake": ["Mindre overtilpasning.", "Bedre ytelse på testdata."],
"true": ["Forenklet beregning.", "Økt sparsitet i modellene."]
},
{
"question": "Hva er viktige trinn i backpropagation?",
"fake": ["Oppdatering av læringsraten.", "Tilfeldig initialisering av vekter.", "Bruk av testdata for evaluering."],
"true": ["Beregning av gradienter."]
},
{
"question": "Hva kan være et symptom på overtilpasning?",
"fake": ["Konstant presisjon over epoker.", "Reduksjon i antall prediksjonsfeil på testdata."],
"true": ["Lav ytelse på testdata.", "Høy ytelse på treningsdata."]
},
{
"question": "Hva er hovedfordelen med k-means clustering?",
"fake": ["Robusthet mot støy.", "Dynamisk oppretting av cluster-typer.", "Evnen til å håndtere ikke-lineær data."],
"true": ["Enkel implementasjon."]
},
{
"question": "Hva er DBSCAN spesielt egnet for?",
"fake": ["Arbeid med datasett med jevne cluster-former.", "Kombinering av lineære funksjoner.", "Oppdeling av data basert på gradienter."],
"true": ["Oppdagelse av outliers."]
},
{
"question": "Hva er et viktig problem i \"curse of dimensionality\"?",
"fake": ["Overrepresentasjon av spesifikke features.", "Mangel på labels."],
"true": ["Økt beregningstid.", "Lavere ytelse for algoritmer."]
},
{
"question": "Hva er formålet med self-supervised learning?",
"fake": ["Å forbedre ytelsen til semi-supervised modeller.", "Å eliminere bruk av all data med labels.", "Å opprette cluster-strukturer automatisk."],
"true": ["Å lage labels fra dataene selv."]
},
{
"question": "Hvilke prinsipper finnes i Explainable AI (XAI)?",
"fake": ["Robusthet.", "Tilpasningsevne."],
"true": ["Transparens.", "Forklarbarhet."]
},
{
"question": "Hvilke etiske prinsipper er sentrale i AI?",
"fake": ["Allokering av ressurser."],
"true": ["Ikke-skade-prinsippet.", "Rettferdighet.", "Velvillighet."]
},
{
"question": "Hva er viktig å vurdere i AI-lovgivning?",
"fake": ["Regulering av lav-risiko AI.", "Maksimal ytelse for AI-systemer."],
"true": ["Risiko-klassifisering.", "Oversikt over general-purpose AI."]
},
{
"question": "Hva representerer \"evidence\" i Bayes’ teorem?",
"fake": ["Klassesannsynligheten.", "Likelihood for dataene gitt klassen.", "Modellens generelle presisjon."],
"true": ["Dataenes sannsynlighetsfordeling."]
},
{
"question": "Hva er \"log-loss\" brukt til i maskinlæring?",
"fake": ["Estimering av sannsynlighet for riktig klassifisering.", "Reduksjon av bias.", "Evaluering av regresjonsmodeller."],
"true": ["Måling av modellens ytelse."]
},
{
"question": "Hva er forskjellen mellom precision og recall?",
"fake": ["Precision evaluerer andel riktige prediksjoner.", "Recall er bedre ved ubalanserte data.", "Precision evaluerer totale klassifiseringsfeil."],
"true": ["Recall evaluerer andel relevante resultater."]
},
    {
      "question": "Hva er hovedmålet med explainable AI (XAI)?",
      "fake": ["Forbedre nøyaktigheten til en modell", "Redusere beregningstid", "Øke antall parametere i en modell"],
      "true": ["Øke forståelsen av hvordan en modell tar avgjørelser"]
    },
    {
      "question": "Hva er en vanlig utfordring med explainable AI?",
      "fake": ["Manglende datasett", "Høy kostnad ved utvikling", "Overfitting på treningsdata"],
      "true": ["Konflikt mellom forklarbarhet og modellens nøyaktighet"]
    },
    {
      "question": "Hvilken metode brukes ofte for å forklare beslutningene til komplekse modeller?",
      "fake": ["SGD (Stochastic Gradient Descent)", "Backpropagation", "Batch Normalization"],
      "true": ["LIME (Local Interpretable Model-agnostic Explanations)"]
    },
    {
      "question": "Hvilken type læring tilhører Q-learning?",
      "fake": ["Veiledet læring", "Uveiledet læring", "Selv-supervisert læring"],
      "true": ["Forsterket læring"]
    },
    {
      "question": "Hva representerer \"Q\" i Q-learning?",
      "fake": ["Quantity of data", "Quantum states", "Question-driven exploration"],
      "true": ["Quality of actions"]
    },
    {
      "question": "Hva er hovedformålet med en Q-tabell i Q-learning?",
      "fake": ["Å lagre alle mulige datasett", "Å visualisere modelleringsresultater", "Å beregne grad av overfitting"],
      "true": ["Å estimere handlingenes verdi i en gitt tilstand"]
    },
    {
      "question": "Hvilken lovgivning regulerer bruken av AI i EU?",
      "fake": ["GDPR", "Data Protection Act", "Digital Services Act"],
      "true": ["AI Act"]
    },
    {
      "question": "Hva er en kjerneidé i AI Act?",
      "fake": ["Forbud mot alle former for AI", "Obligatorisk bruk av AI i offentlig sektor", "Subsidiering av AI-forskning"],
      "true": ["Risikobasert tilnærming til AI-regulering"]
    },
    {
      "question": "Hvilket nivå av risiko vurderes i AI Act?",
      "fake": ["Lav, middels og høy risiko", "Godkjent og ikke-godkjent", "Sikker og usikker AI"],
      "true": ["Minimal, begrenset, høy og uakseptabel risiko"]
    },
    {
      "question": "Hvordan defineres explainable AI?",
      "fake": ["AI som maksimerer ytelse uten hensyn til forståelighet", "AI som bruker heuristiske metoder", "AI som bruker minimalt med ressurser"],
      "true": ["AI som produserer forklaringer på sine beslutninger"]
    },
        {
          "question": "Hvilket av følgende er et eksempel på en forklarbar modell?",
          "fake": ["Nevrale nettverk", "Random Forests", "Generative Adversarial Networks (GANs)"],
          "true": ["Lineær regresjon"]
        },
        {
          "question": "Hvilken metode brukes ofte for å visualisere modellenes beslutningsprosess?",
          "fake": ["LSTM (Long Short-Term Memory)", "Dropout", "Regularisering"],
          "true": ["SHAP (Shapley Additive Explanations)"]
        },
        {
          "question": "Hvilken læringsstrategi benytter Q-learning?",
          "fake": ["Reduksjon av tap", "Klustering", "Klassifisering"],
          "true": ["Belønningsmaksimering"]
        },
        {
          "question": "Hva er en kritisk komponent i Q-learning?",
          "fake": ["Hyperparameter-justering", "Datakoding", "Cross-validation"],
          "true": ["Discount-faktor (γ)"]
        },
        {
          "question": "Hva betyr discount-faktoren (γ) i Q-learning?",
          "fake": ["Hastigheten til algoritmen", "Nøyaktigheten til modellen", "Modellenes kompleksitet"],
          "true": ["Hvor mye fremtidige belønninger verdsettes"]
        },
        {
          "question": "Hvilket prinsipp driver explainable AI?",
          "fake": ["Maksimer ytelse, uansett kompleksitet", "Reduksjon av treningskostnader", "Ubegrenset datatilgang"],
          "true": ["Etisk og gjennomsiktig beslutningstaking"]
        },
        {
          "question": "Hva betyr begrepet \"high-risk AI systemer\" i AI Act?",
          "fake": ["Systemer som alltid feiler", "AI med høy beregningskostnad", "Systemer som er umulige å forklare"],
          "true": ["AI som kan påvirke enkeltpersoners rettigheter eller sikkerhet"]
        },
        {
          "question": "Hva er en fordel med explainable AI?",
          "fake": ["Bedre modellnøyaktighet", "Mindre datakrav", "Kortere treningstid"],
          "true": ["Økt brukertillit og aksept"]
        },
        {
          "question": "I forsterket læring, hva er \"policy\"?",
          "fake": ["En evaluering av treningsdatasett", "En tapsfunksjon", "En teknikk for klustering"],
          "true": ["En regel for hvordan handlinger utføres"]
        },
        {
          "question": "Hvordan evalueres en policy i Q-learning?",
          "fake": ["Ved å bruke F1-score", "Gjennom regresjonsanalyser", "Ved å analysere tapshistorikk"],
          "true": ["Basert på handlingenes samlede forventede belønning"]
        },
        {
          "question": "Hva er formålet med AI Act?",
          "fake": ["Å forby all uveiledet læring", "Å eliminere bruken av store datasett", "Å tvinge alle til å bruke AI"],
          "true": ["Å balansere innovasjon og regulering i AI"]
        },
        {
          "question": "Hvilket av følgende er ikke en teknikk for explainable AI?",
          "fake": ["LIME", "SHAP", "Decision Trees"],
          "true": ["Hyperparameter-optimalisering"]
        },
        {
          "question": "Hva er en viktig begrensning i explainable AI?",
          "fake": ["Utilgjengelige treningsdata", "Mangel på datasett", "Redusert treningshastighet"],
          "true": ["Begrenset forklarbarhet for svært komplekse modeller"]
        },
        {
          "question": "Hva er den viktigste fordelen med Q-learning?",
          "fake": ["Det krever mindre data", "Det trenger ikke belønningssystemer", "Det unngår all form for overfitting"],
          "true": ["Det krever ingen modell for miljøet"]
        },
        {
          "question": "Hvilken rolle spiller målemetrikker i explainable AI?",
          "fake": ["Optimalisere modellens kompleksitet", "Redusere ressursbruk", "Tilpasse algoritmens arkitektur"],
          "true": ["Evaluere ytelsen på en forståelig måte"]
        },
        {
          "question": "Hva innebærer \"policy iteration\" i Q-learning?",
          "fake": ["Å iterere over ulike treningsdatasett", "Å endre modellens arkitektur", "Å redusere kompleksiteten i policy"],
          "true": ["Å oppdatere policy basert på forventede belønninger"]
        },
        {
          "question": "Hva er hovedårsaken til AI Act?",
          "fake": ["For å begrense innovasjon innen AI", "For å redusere kostnader ved AI-utvikling", "For å forby maskinlæringsmodeller"],
          "true": ["For å unngå uregulert bruk av AI"]
        },
        {
          "question": "Hvilket av følgende systemer klassifiseres som uakseptabel risiko i AI Act?",
          "fake": ["Anbefalingssystemer", "Maskinoversettelsessystemer", "Spillestrategier"],
          "true": ["Sosiale scoring-systemer"]
        },
        {
          "question": "Hva er hovedutfordringen ved uetisk bruk av AI?",
          "fake": ["Lav forklarbarhet", "Forhøyede treningskostnader", "Manglende innovasjon"],
          "true": ["Skader på individers rettigheter"]
        },
        {
          "question": "Hvordan kan explainable AI hjelpe organisasjoner?",
          "fake": ["Ved å redusere modellens kompleksitet", "Ved å fjerne krav til databehandling", "Ved å øke antall parametere i modellen"],
          "true": ["Ved å styrke tilliten til beslutningene som tas av AI"]
        },
            {
              "question": "Hva er et eksempel på en forklaringsmetode som er modell-agnostisk?",
              "fake": ["Logistisk regresjon", "Nevrale nettverk", "Support Vector Machines (SVM)"],
              "true": ["SHAP"]
            },
            {
              "question": "Hva er hovedmålet med discount-faktoren i Q-learning?",
              "fake": ["Å redusere modellens kompleksitet", "Å øke prediksjonspresisjonen", "Å optimalisere hyperparametere"],
              "true": ["Å balansere nåværende og fremtidige belønninger"]
            },
            {
              "question": "Hvordan skiller explainable AI seg fra tradisjonell AI?",
              "fake": ["Fokus på ytelse fremfor gjennomsiktighet", "Reduksjon av datasettets størrelse", "Økt kompleksitet i modellene"],
              "true": ["Fokus på forståelige forklaringer"]
            },
            {
              "question": "Hva er en vanlig metode for å visualisere policy i Q-learning?",
              "fake": ["ROC-kurver", "Gradient descent-plott", "Scatterplots"],
              "true": ["Heatmaps av Q-tabeller"]
            },
            {
              "question": "Hvilken risiko vurderes som akseptabel i AI Act?",
              "fake": ["Uakseptabel risiko", "Høy risiko", "Kritisk risiko"],
              "true": ["Begrenset risiko"]
            },
            {
              "question": "Hvilket element er ikke relevant for forklarbar AI?",
              "fake": ["Transparens", "Tilgjengelighet av data", "Presisjon av forklaringer"],
              "true": ["Overfitting"]
            },
            {
              "question": "Hvordan trenes Q-learning?",
              "fake": ["Ved optimalisering av en tapsfunksjon", "Ved krysstrening med andre modeller", "Ved å bruke veiledet læring"],
              "true": ["Ved iterativ oppdatering av Q-tabellen basert på belønning"]
            },
            {
              "question": "Hva er en viktig komponent i AI Act?",
              "fake": ["Forbud mot all AI som bruker maskinlæring", "Obligatorisk bruk av spesifikke algoritmer", "Subsidiering av AI-forskning"],
              "true": ["Risikobasert klassifisering av AI-applikasjoner"]
            },
            {
              "question": "Hvilken av følgende metoder bidrar til explainable AI?",
              "fake": ["Bagging", "Boosting", "Dropout"],
              "true": ["Feature importance-plott"]
            },
            {
              "question": "Hva er formålet med reward-funksjonen i Q-learning?",
              "fake": ["Å optimalisere modellen direkte", "Å forklare modellens beslutninger", "Å evaluere datasettets egenskaper"],
              "true": ["Å gi umiddelbar tilbakemelding på en handling"]
            },
            {
              "question": "Hvordan definerer AI Act \"høy risiko\"-systemer?",
              "fake": ["AI-systemer som er dyre å trene", "Alle AI-systemer som bruker dype nevrale nettverk", "Systemer som krever manuell overvåking"],
              "true": ["Systemer som kan påvirke folks sikkerhet eller rettigheter negativt"]
            },
            {
              "question": "Hva er en viktig fordel med explainable AI i helsevesenet?",
              "fake": ["Redusert kostnad for modellutvikling", "Mindre databehov", "Hurtigere modelltrening"],
              "true": ["Bedre forståelse av beslutningsprosessen for pasientdiagnose"]
            },
            {
              "question": "Hva representerer handlingene i Q-learning?",
              "fake": ["Resultater av en prediksjon", "Variabler i treningsdata", "Parametere i modellen"],
              "true": ["Alternativer som kan velges i en gitt tilstand"]
            },
            {
              "question": "Hvilken av følgende metoder øker forklarbarheten i komplekse modeller?",
              "fake": ["Dropout", "Regularisering", "Batch Normalization"],
              "true": ["LIME"]
            },
            {
              "question": "Hva er en kritisk utfordring i Q-learning?",
              "fake": ["Begrensede datasett", "Utilgjengelighet av Q-tabellen", "Overdrevet forklarbarhet"],
              "true": ["Balansere eksplorasjon og utnyttelse"]
            },
            {
              "question": "Hvordan kan explainable AI bidra til juridisk etterlevelse?",
              "fake": ["Ved å redusere utviklingskostnader", "Ved å øke modellens kompleksitet", "Ved å unngå bruk av sensitive data"],
              "true": ["Ved å gi gjennomsiktige forklaringer som kan granskes"]
            },
            {
              "question": "Hva er en hovedutfordring i utviklingen av explainable AI?",
              "fake": ["Redusert modellens ytelse", "Økte krav til datasettstørrelse", "Begrensninger på hardware"],
              "true": ["Forklaringer som er for komplekse for sluttbrukere"]
            },
            {
              "question": "Hva gjør Q-learning modell-fri?",
              "fake": ["Den bruker ikke treningsdata", "Den krever ingen tapsfunksjon", "Den eliminerer alle parametere"],
              "true": ["Den trenger ikke en eksplisitt modell av miljøet"]
            },
            {
              "question": "Hvordan klassifiserer AI Act sosiale scoring-systemer?",
              "fake": ["Begrenset risiko", "Høy risiko", "Ingen risiko"],
              "true": ["Uakseptabel risiko"]
            },
            {
              "question": "Hvilken rolle spiller explainable AI i offentlige beslutninger?",
              "fake": ["Reduserer kompleksiteten i offentlige systemer", "Optimaliserer offentlige budsjetter", "Øker automatiseringshastigheten"],
              "true": ["Gir tillit og forståelse i sensitive beslutningsprosesser"]
            },
            {
                "question": "Which of the following statements about Linear Regression in machine learning are correct? Select all that apply.",
                "fake": [
                  "Linear Regression inherently performs feature selection and will remove irrelevant predictors automatically.",
                  "Linear Regression requires that residuals are normally distributed for the model to be valid.",
                  "Linear Regression is unaffected by outliers, making it a robust modeling technique.",
                  "Linear Regression requires all predictor variables to be standardized or normalized.",
                  "Linear Regression is suitable only for time-series data and cannot be applied to cross-sectional data.",
                  "In Linear Regression, adding more predictors always increases the predictive accuracy on unseen data."
                ],
                "true": [
                  "Linear Regression assumes a linear relationship between the independent variables and the dependent variable.",
                  "Ordinary Least Squares (OLS) Linear Regression estimates coefficients by minimizing the sum of squared residuals.",
                  "Linear Regression can be extended to handle polynomial relationships by adding transformed features, such as squared or interaction terms.",
                  "Multicollinearity among predictors can cause instability in the coefficient estimates of a Linear Regression model.",
                  "Including too many correlated variables in Linear Regression can lead to overfitting.",
                  "Linear Regression can be solved analytically when using the closed-form solution of the normal equations.",
                  "Gradient Descent is an alternative method to find the coefficients of a Linear Regression model, especially when the number of features is large.",
                  "Linear Regression models the conditional expectation of the response variable given the predictors as a linear function.",
                  "Linear Regression typically assumes that variance of the residuals is constant (homoscedasticity).",
                  "The R-squared metric is commonly used to measure how well a Linear Regression model fits the data.",
                  "Regularization methods like Ridge or Lasso can be applied to Linear Regression to address overfitting.",
                  "Linear Regression can output negative coefficient values even if all observed data points are positive.",
                  "One common assumption in Linear Regression is the independence of residuals.",
                  "Linear Regression can handle both continuous and categorical predictors (after encoding categorical variables).",
                  "Linear Regression is the simplest form of supervised machine learning used for regression tasks.",
                  "Gradient-based optimization methods for Linear Regression require differentiability of the loss function.",
                  "Linear Regression provides confidence intervals for the estimated regression coefficients under certain statistical assumptions.",
                  "If the relationship between predictors and response is nonlinear, applying Linear Regression directly may result in a poor fit.",
                  "Linear Regression coefficients can be interpreted as the expected change in the response variable for a one-unit change in the predictor, holding other predictors constant."
                ]
              }
              
          ]
          
      
  









